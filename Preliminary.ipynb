{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preliminary",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SLTHRN/Heart_disease_ML/blob/main/Preliminary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1crVSsbrrF3T"
      },
      "source": [
        "#IMPORT LIBRARIES\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP4l01-QZ1LP",
        "outputId": "1f0a5a84-3e2f-40d0-ae56-d157fc5e3c17"
      },
      "source": [
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f06bfb6f9f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIEuRHBSByOu"
      },
      "source": [
        "### IMPORTING CSV FILE FROM GOOGLE DRIVE\n",
        "\n",
        "import csv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#FILE LOCATION IN GOOGLE DRIVE\n",
        "directory = '/content/drive/MyDrive/APS360PROJECT/New data.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp3sdcq8r8ye"
      },
      "source": [
        "### DEFINING CNN MODEL NETWORK\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#DEFINING A 3 LAYER FULLY CONNECTED MODEL\n",
        "class neuralNetwork(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(neuralNetwork, self).__init__()\n",
        "    self.layer1 = nn.Linear(13,50)\n",
        "    self.layer2 = nn.Linear(50,70)\n",
        "    self.layer3 = nn.Linear(70,4)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #x = x.squeeze()\n",
        "    activation1 = self.layer1(x)\n",
        "    activation1 = F.relu(activation1)\n",
        "    activation2 = F.relu(self.layer2(activation1))\n",
        "    output = self.layer3(activation2)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9th9wE30YjIc"
      },
      "source": [
        "### PANDAS\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv(directory)\n",
        "\n",
        "dataset = dataset.iloc()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B93RhGcPYusq",
        "outputId": "5cab367d-f8bc-41bf-86ac-8e6b7e546273"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Unnamed: 0  Age  Sex  ...  Major_Vessels  Thalessemia  Target\n",
            "0             0   63    1  ...              0            6       0\n",
            "1             1   67    1  ...              3            3       2\n",
            "2             2   67    1  ...              2            7       1\n",
            "3             3   37    1  ...              0            3       0\n",
            "4             4   41    0  ...              0            3       0\n",
            "..          ...  ...  ...  ...            ...          ...     ...\n",
            "292         297   57    0  ...              0            7       1\n",
            "293         298   45    1  ...              0            7       1\n",
            "294         299   68    1  ...              2            7       2\n",
            "295         300   57    1  ...              1            7       3\n",
            "296         301   57    0  ...              1            3       1\n",
            "\n",
            "[297 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1Bel7QJGtiG"
      },
      "source": [
        "### LOADING CSV FILE FROM DIRECTORY\n",
        "\n",
        "file = open(directory, \"r\")\n",
        "retrieved = csv.reader(file)\n",
        "\n",
        "data_size = -1\n",
        "dictionary = {}\n",
        "data = []\n",
        "\n",
        "\n",
        "### RETRIEVING DATA FROM CSV FILE\n",
        "\n",
        "for row in retrieved:\n",
        "  data_size += 1  # This counts the number of rows produced\n",
        "\n",
        "  if data_size == 0:\n",
        "    for i in range(len(row)):\n",
        "      dictionary[i] = row[i]\n",
        "\n",
        "  else:\n",
        "    data.append(row)\n",
        "\n",
        "\n",
        "for i in data:\n",
        "  del i[0]\n",
        "  del i []\n",
        "del dictionary[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9goRgyl4MzU-",
        "outputId": "269eaa39-5709-48b4-beb7-0d804ed2f014"
      },
      "source": [
        "print(dictionary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 'Age', 2: 'Sex', 3: 'Chest_Pain', 4: 'Resting_Blood_Pressure', 5: 'Colestrol', 6: 'Fasting_Blood_Sugar', 7: 'Rest_ECG', 8: 'MAX_Heart_Rate', 9: 'Exercised_Induced_Angina', 10: 'ST_Depression', 11: 'Slope', 12: 'Major_Vessels', 13: 'Thalessemia', 14: 'Target'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwvsdmimYkh4"
      },
      "source": [
        "### TURNING STRING TO FLOAT\n",
        "\n",
        "fail_count = 0\n",
        "new_data = data.copy()\n",
        "\n",
        "for i in range(len(data)):\n",
        "\n",
        "  row = data[i]\n",
        "  new_row = []\n",
        "\n",
        "  for j in range(len(row)):\n",
        "    if row[j].isnumeric():\n",
        "      new_row.append(float(row[j]))\n",
        "    else:\n",
        "      test = row[j].split('.')\n",
        "      if len(test) == 2 and (test[0].isnumeric and test[1].isnumeric):\n",
        "        new_row.append(float(row[j]))\n",
        "\n",
        "      else:\n",
        "        print('!!!!!!!!!!!!!!!!!!!!!!!!!!!'+test[0])\n",
        "\n",
        "        print('Not Numeric --------')\n",
        "        fail_count += 1\n",
        "        print('fail = ' + str(fail_count))\n",
        "        new_row.append(row[j])\n",
        "\n",
        "  data[i] = new_row\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR1G30XWOM51"
      },
      "source": [
        "### GENERATING SAMPLERS FOR THE DATALOADERS\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "index = torch.randperm(data_size)\n",
        "\n",
        "end_training = int(len(index)*0.6) # Defining index for last data sample in training set\n",
        "end_validation = end_training + int(len(index)*0.2) # Defining index for last data sample in validation set\n",
        "\n",
        "training_sampler, validation_sampler, testing_sampler = index[:end_training], index[end_training:end_validation], index[end_validation:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7-nneEVN_fz"
      },
      "source": [
        "### DEFINING HYPERPARAMETERS\n",
        "\n",
        "batch_size = 10\n",
        "learning_rate = 0.01\n",
        "epochs = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e7SFfd3L2HI"
      },
      "source": [
        "### DEFINING LOADERS FOR TRAINING, VALIDATION, & TESTING DATA\n",
        "\n",
        "dataset = torch.tensor(data)\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size = batch_size, sampler = training_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size = batch_size, sampler = validation_sampler)\n",
        "testing_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size = batch_size, sampler = testing_sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoxNnY9-XgTJ",
        "outputId": "c065df75-e550-4d5b-86eb-bd26d872e62b"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[63.,  1.,  1.,  ...,  0.,  6.,  0.],\n",
            "        [67.,  1.,  4.,  ...,  3.,  3.,  2.],\n",
            "        [67.,  1.,  4.,  ...,  2.,  7.,  1.],\n",
            "        ...,\n",
            "        [68.,  1.,  4.,  ...,  2.,  7.,  2.],\n",
            "        [57.,  1.,  4.,  ...,  1.,  7.,  3.],\n",
            "        [57.,  0.,  2.,  ...,  1.,  3.,  1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "LwsZIvQv3Jj1",
        "outputId": "bb59bf7f-3212-4ef9-c419-adacb28242d4"
      },
      "source": [
        "import time\n",
        "import torch.optim as optim\n",
        "\n",
        "model = neuralNetwork()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "iters, losses, train_acc, val_acc = [], [], [], []\n",
        "n = 0 # number of iterations\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  for batch in training_loader:\n",
        "    for data in batch:\n",
        "      print(data.size())\n",
        "      label = torch.tensor(data[len(data)-1])\n",
        "      label = torch.reshape(label, (1,1))\n",
        "      label = torch.squeeze(label, 1)\n",
        "      print(label.size())\n",
        "      print(\"input\")\n",
        "      input = torch.tensor(data[:len(data)-1])\n",
        "\n",
        "      print(input)\n",
        "      print('label')\n",
        "      print(label)\n",
        "\n",
        "      output = model(input.type(torch.FloatTensor))\n",
        "\n",
        "      print('output')\n",
        "      print(output)\n",
        "\n",
        "      loss = criterion(output, label)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"for epoch in range(epochs):\n",
        "  for batch in training_loader:\n",
        "\n",
        "    #print(batch)\n",
        "    #print(batch[0][0])\n",
        "    #print(batch[len(batch[0])-1][:])\n",
        "    stuffs = batch\n",
        "    array=stuffs.empty()\n",
        "    print(array)\n",
        "    #input = stuffs.np()\n",
        "\n",
        "\n",
        "\n",
        "    input = torch.tensor(batch[:][:len(data)-1])\n",
        "    label = torch.tensor(batch[:][len(data)-1])\n",
        "\n",
        "    output = model(input.tp(torch.FloatTensor))\n",
        "\n",
        "    loss = citerion(out,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    iters.append(n)\n",
        "    losses.append(float(loss)/batch_size)\n",
        "    train_acc.append(get_accuracy(model, train=True))\n",
        "    val_acc.append(get_accuracy(model, train = False))\n",
        "\n",
        "    n += 1\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-54debbd094c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'neuralNetwork' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkz9PbKyE0Hr"
      },
      "source": [
        "###########################\n",
        "  \"\"\"label = torch.tensor(data[:len(data[0]-1)][:])\n",
        "  input = torch.tensor(data[:len(data[0])-2][:])\n",
        "  output = model(input)\n",
        "\n",
        "  loss = citerion(output, actual)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "error = 0\n",
        "for batch in training_loader:\n",
        "  label = torch.tensor(data[:len(data[0]-1)][:])\n",
        "  input = torch.tensor(data[:len(data[0])-2][:])\n",
        "  \n",
        "  prob = F.relu(model(input))\n",
        "  if (prob < 0.5 and label > 0) or (prob > 0.5 and label == 0):\n",
        "    error += 1\n",
        "\n",
        "print(\"training Error Rate:\", error/len(training_loader))\n",
        "print(\"Training Accuracy:\", 1 - error/len(training_loader))\n",
        "\n",
        "error = 0\n",
        "for batch in testing_loader:\n",
        "  label = torch.tensor(data[:len(data[0]-1)][:])\n",
        "  input = torch.tensor(data[:len(data[0])-2][:])\n",
        "  \n",
        "  prob = F.relu(model(input))\n",
        "  if (prob < 0.5 and label > 0) or (prob > 0.5 and label == 0):\n",
        "    error += 1\n",
        "\n",
        "print(\"Test Error Rate:\", error/len(testing_loader))\n",
        "print(\"Test Accuracy:\", 1 - error/len(testing_loader))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P25ZpAk0zsFw",
        "outputId": "f1766b59-0157-4429-b236-b8c3cff518b3"
      },
      "source": [
        "count = 0\n",
        "for data in training_loader:\n",
        "  count += 1\n",
        "  if count == 5:\n",
        "    break\n",
        "  else:\n",
        "    print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 57.0000,   0.0000,   2.0000, 130.0000, 236.0000,   0.0000,   2.0000,\n",
            "         174.0000,   0.0000,   0.0000,   2.0000,   1.0000,   3.0000,   1.0000],\n",
            "        [ 63.0000,   1.0000,   1.0000, 145.0000, 233.0000,   1.0000,   2.0000,\n",
            "         150.0000,   0.0000,   2.3000,   3.0000,   0.0000,   6.0000,   0.0000],\n",
            "        [ 57.0000,   1.0000,   4.0000, 130.0000, 131.0000,   0.0000,   0.0000,\n",
            "         115.0000,   1.0000,   1.2000,   2.0000,   1.0000,   7.0000,   3.0000],\n",
            "        [ 65.0000,   0.0000,   3.0000, 160.0000, 360.0000,   0.0000,   2.0000,\n",
            "         151.0000,   0.0000,   0.8000,   1.0000,   0.0000,   3.0000,   0.0000],\n",
            "        [ 68.0000,   1.0000,   4.0000, 144.0000, 193.0000,   1.0000,   0.0000,\n",
            "         141.0000,   0.0000,   3.4000,   2.0000,   2.0000,   7.0000,   2.0000],\n",
            "        [ 55.0000,   0.0000,   4.0000, 180.0000, 327.0000,   0.0000,   1.0000,\n",
            "         117.0000,   1.0000,   3.4000,   2.0000,   0.0000,   3.0000,   2.0000],\n",
            "        [ 60.0000,   0.0000,   1.0000, 150.0000, 240.0000,   0.0000,   0.0000,\n",
            "         171.0000,   0.0000,   0.9000,   1.0000,   0.0000,   3.0000,   0.0000],\n",
            "        [ 51.0000,   0.0000,   3.0000, 120.0000, 295.0000,   0.0000,   2.0000,\n",
            "         157.0000,   0.0000,   0.6000,   1.0000,   0.0000,   3.0000,   0.0000],\n",
            "        [ 43.0000,   1.0000,   4.0000, 110.0000, 211.0000,   0.0000,   0.0000,\n",
            "         161.0000,   0.0000,   0.0000,   1.0000,   0.0000,   7.0000,   0.0000],\n",
            "        [ 42.0000,   0.0000,   3.0000, 120.0000, 209.0000,   0.0000,   0.0000,\n",
            "         173.0000,   0.0000,   0.0000,   2.0000,   0.0000,   3.0000,   0.0000]])\n",
            "tensor([[6.5000e+01, 0.0000e+00, 4.0000e+00, 1.5000e+02, 2.2500e+02, 0.0000e+00,\n",
            "         2.0000e+00, 1.1400e+02, 0.0000e+00, 1.0000e+00, 2.0000e+00, 3.0000e+00,\n",
            "         7.0000e+00, 4.0000e+00],\n",
            "        [6.8000e+01, 0.0000e+00, 3.0000e+00, 1.2000e+02, 2.1100e+02, 0.0000e+00,\n",
            "         2.0000e+00, 1.1500e+02, 0.0000e+00, 1.5000e+00, 2.0000e+00, 0.0000e+00,\n",
            "         3.0000e+00, 0.0000e+00],\n",
            "        [5.8000e+01, 1.0000e+00, 4.0000e+00, 1.0000e+02, 2.3400e+02, 0.0000e+00,\n",
            "         0.0000e+00, 1.5600e+02, 0.0000e+00, 1.0000e-01, 1.0000e+00, 1.0000e+00,\n",
            "         7.0000e+00, 2.0000e+00],\n",
            "        [4.7000e+01, 1.0000e+00, 4.0000e+00, 1.1000e+02, 2.7500e+02, 0.0000e+00,\n",
            "         2.0000e+00, 1.1800e+02, 1.0000e+00, 1.0000e+00, 2.0000e+00, 1.0000e+00,\n",
            "         3.0000e+00, 1.0000e+00],\n",
            "        [5.0000e+01, 0.0000e+00, 3.0000e+00, 1.2000e+02, 2.1900e+02, 0.0000e+00,\n",
            "         0.0000e+00, 1.5800e+02, 0.0000e+00, 1.6000e+00, 2.0000e+00, 0.0000e+00,\n",
            "         3.0000e+00, 0.0000e+00],\n",
            "        [6.7000e+01, 1.0000e+00, 4.0000e+00, 1.2500e+02, 2.5400e+02, 1.0000e+00,\n",
            "         0.0000e+00, 1.6300e+02, 0.0000e+00, 2.0000e-01, 2.0000e+00, 2.0000e+00,\n",
            "         7.0000e+00, 3.0000e+00],\n",
            "        [5.2000e+01, 1.0000e+00, 4.0000e+00, 1.1200e+02, 2.3000e+02, 0.0000e+00,\n",
            "         0.0000e+00, 1.6000e+02, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
            "         3.0000e+00, 1.0000e+00],\n",
            "        [6.7000e+01, 1.0000e+00, 3.0000e+00, 1.5200e+02, 2.1200e+02, 0.0000e+00,\n",
            "         2.0000e+00, 1.5000e+02, 0.0000e+00, 8.0000e-01, 2.0000e+00, 0.0000e+00,\n",
            "         7.0000e+00, 1.0000e+00],\n",
            "        [4.5000e+01, 0.0000e+00, 2.0000e+00, 1.1200e+02, 1.6000e+02, 0.0000e+00,\n",
            "         0.0000e+00, 1.3800e+02, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
            "         3.0000e+00, 0.0000e+00],\n",
            "        [5.5000e+01, 0.0000e+00, 2.0000e+00, 1.3200e+02, 3.4200e+02, 0.0000e+00,\n",
            "         0.0000e+00, 1.6600e+02, 0.0000e+00, 1.2000e+00, 1.0000e+00, 0.0000e+00,\n",
            "         3.0000e+00, 0.0000e+00]])\n",
            "tensor([[ 62.0000,   0.0000,   4.0000, 140.0000, 268.0000,   0.0000,   2.0000,\n",
            "         160.0000,   0.0000,   3.6000,   3.0000,   2.0000,   3.0000,   3.0000],\n",
            "        [ 66.0000,   0.0000,   3.0000, 146.0000, 278.0000,   0.0000,   2.0000,\n",
            "         152.0000,   0.0000,   0.0000,   2.0000,   1.0000,   3.0000,   0.0000],\n",
            "        [ 54.0000,   0.0000,   3.0000, 135.0000, 304.0000,   1.0000,   0.0000,\n",
            "         170.0000,   0.0000,   0.0000,   1.0000,   0.0000,   3.0000,   0.0000],\n",
            "        [ 52.0000,   1.0000,   1.0000, 152.0000, 298.0000,   1.0000,   0.0000,\n",
            "         178.0000,   0.0000,   1.2000,   2.0000,   0.0000,   7.0000,   0.0000],\n",
            "        [ 48.0000,   1.0000,   4.0000, 122.0000, 222.0000,   0.0000,   2.0000,\n",
            "         186.0000,   0.0000,   0.0000,   1.0000,   0.0000,   3.0000,   0.0000],\n",
            "        [ 58.0000,   0.0000,   4.0000, 170.0000, 225.0000,   1.0000,   2.0000,\n",
            "         146.0000,   1.0000,   2.8000,   2.0000,   2.0000,   6.0000,   2.0000],\n",
            "        [ 35.0000,   1.0000,   4.0000, 126.0000, 282.0000,   0.0000,   2.0000,\n",
            "         156.0000,   1.0000,   0.0000,   1.0000,   0.0000,   7.0000,   1.0000],\n",
            "        [ 35.0000,   0.0000,   4.0000, 138.0000, 183.0000,   0.0000,   0.0000,\n",
            "         182.0000,   0.0000,   1.4000,   1.0000,   0.0000,   3.0000,   0.0000],\n",
            "        [ 64.0000,   0.0000,   4.0000, 180.0000, 325.0000,   0.0000,   0.0000,\n",
            "         154.0000,   1.0000,   0.0000,   1.0000,   0.0000,   3.0000,   0.0000],\n",
            "        [ 40.0000,   1.0000,   4.0000, 110.0000, 167.0000,   0.0000,   2.0000,\n",
            "         114.0000,   1.0000,   2.0000,   2.0000,   0.0000,   7.0000,   3.0000]])\n",
            "tensor([[6.2000e+01, 0.0000e+00, 4.0000e+00, 1.3800e+02, 2.9400e+02, 1.0000e+00,\n",
            "         0.0000e+00, 1.0600e+02, 0.0000e+00, 1.9000e+00, 2.0000e+00, 3.0000e+00,\n",
            "         3.0000e+00, 2.0000e+00],\n",
            "        [5.8000e+01, 1.0000e+00, 3.0000e+00, 1.1200e+02, 2.3000e+02, 0.0000e+00,\n",
            "         2.0000e+00, 1.6500e+02, 0.0000e+00, 2.5000e+00, 2.0000e+00, 1.0000e+00,\n",
            "         7.0000e+00, 4.0000e+00],\n",
            "        [3.7000e+01, 1.0000e+00, 3.0000e+00, 1.3000e+02, 2.5000e+02, 0.0000e+00,\n",
            "         0.0000e+00, 1.8700e+02, 0.0000e+00, 3.5000e+00, 3.0000e+00, 0.0000e+00,\n",
            "         3.0000e+00, 0.0000e+00],\n",
            "        [6.3000e+01, 1.0000e+00, 4.0000e+00, 1.3000e+02, 2.5400e+02, 0.0000e+00,\n",
            "         2.0000e+00, 1.4700e+02, 0.0000e+00, 1.4000e+00, 2.0000e+00, 1.0000e+00,\n",
            "         7.0000e+00, 2.0000e+00],\n",
            "        [6.3000e+01, 0.0000e+00, 4.0000e+00, 1.5000e+02, 4.0700e+02, 0.0000e+00,\n",
            "         2.0000e+00, 1.5400e+02, 0.0000e+00, 4.0000e+00, 2.0000e+00, 3.0000e+00,\n",
            "         7.0000e+00, 4.0000e+00],\n",
            "        [3.9000e+01, 1.0000e+00, 3.0000e+00, 1.4000e+02, 3.2100e+02, 0.0000e+00,\n",
            "         2.0000e+00, 1.8200e+02, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
            "         3.0000e+00, 0.0000e+00],\n",
            "        [6.2000e+01, 1.0000e+00, 2.0000e+00, 1.2000e+02, 2.8100e+02, 0.0000e+00,\n",
            "         2.0000e+00, 1.0300e+02, 0.0000e+00, 1.4000e+00, 2.0000e+00, 1.0000e+00,\n",
            "         7.0000e+00, 3.0000e+00],\n",
            "        [6.0000e+01, 0.0000e+00, 4.0000e+00, 1.5000e+02, 2.5800e+02, 0.0000e+00,\n",
            "         2.0000e+00, 1.5700e+02, 0.0000e+00, 2.6000e+00, 2.0000e+00, 2.0000e+00,\n",
            "         7.0000e+00, 3.0000e+00],\n",
            "        [6.4000e+01, 0.0000e+00, 3.0000e+00, 1.4000e+02, 3.1300e+02, 0.0000e+00,\n",
            "         0.0000e+00, 1.3300e+02, 0.0000e+00, 2.0000e-01, 1.0000e+00, 0.0000e+00,\n",
            "         7.0000e+00, 0.0000e+00],\n",
            "        [4.9000e+01, 1.0000e+00, 3.0000e+00, 1.1800e+02, 1.4900e+02, 0.0000e+00,\n",
            "         2.0000e+00, 1.2600e+02, 0.0000e+00, 8.0000e-01, 1.0000e+00, 3.0000e+00,\n",
            "         3.0000e+00, 1.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnK2L7xtxzZI"
      },
      "source": [
        "import time\n",
        "\n",
        "def training(net, bs, lr, epochs):\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "\n",
        "  train_error = np.zeros(epochs)\n",
        "  train_loss = np.zeros(epochs)\n",
        "  val_error = np.zeros(epochs)\n",
        "  val_loss = np.zeros(epochs)\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  for e in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_error = 0.0\n",
        "    total_epoch = 0\n",
        "\n",
        "    for data in loader:\n",
        "      inputs = data[:][:12]\n",
        "      labels = data[:][13]\n",
        "      optimizer.zero_grad()\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      corr = (output > 0.0).squeeze().long() != labels\n",
        "      total_train_err += int(corr.sum())\n",
        "      total_rain_loss += loss.item()\n",
        "      total_epoch += len(labels)\n",
        "    train_err[epoch] = float(total_train_err) / total_epoch\n",
        "    train_loss[epoch] = float(total_train_loss) / (i+1)\n",
        "    val_err[epoch], val_loss[epoch] = evaluate(net, val_loader, criterion)\n",
        "    print((\"epoch {}: Train err: [], Train loss: [] |\" + \"Validation err: {}, Validation loss: {}\").format(epoch +1,\n",
        "                                                                                                           train_err[epoch],\n",
        "                                                                                                           train_loss[epoch],\n",
        "                                                                                                           val_err[epoch],\n",
        "                                                                                                           val_loss[epoch]))\n",
        "    model_path = get_model_name(model.name, batch_size, lr, epoch)\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print('Finished Training')\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
        "    epochs = np.arrange(1, num_epochs + 1)\n",
        "    np.savetxt(\"{}_train_err.csv\".format(model_path), train_err)\n",
        "    np.savetxt(\"{}_train_loss.csv\".format(model_path), train_loss)\n",
        "    np.savetxt(\"{}_val_err.csv\".format(model_path), val_err)\n",
        "    np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIjOAurI1_C3"
      },
      "source": [
        "def evaluate(model, loader, criterion):\n",
        "  total_loss = 0.0\n",
        "  total_err = 0.0\n",
        "  total_epoch = 0\n",
        "  for data in loader:\n",
        "    inputs = data[:][:12]\n",
        "    labels = data[:][13]\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels.float())\n",
        "    corr = (outputs > 0.0) != labels\n",
        "    total_err +=int(corr.sum())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N_eIvhz1fRp"
      },
      "source": [
        "model = neuralNetwork()\n",
        "\n",
        "training(model, bs = batch_size, lr = learning_rate, epochs = epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6um6ftAw4tn"
      },
      "source": [
        "def get_accuracy(model, traing = False):\n",
        "  if train:\n",
        "    data = _\n",
        "  else:\n",
        "    data = mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaPi5aLfAUeZ"
      },
      "source": [
        "### DEFINING TRAINING OF MODEL\n",
        "\n",
        "def training(model, data, training, validation, num_epochs, lr, bs):\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "  train_loader = torch.utils.data.DataLoader(dataset = data, batch_size = bs, sampler = training)\n",
        "\n",
        "  epochs, losses, train_acc, valid_acc = [], [], [], []\n",
        "\n",
        "  n = 0\n",
        "  for epoch in range(num_epochs):\n",
        "    for values, labels in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      output = model(values)\n",
        "\n",
        "      loss = criterion(pred, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      iters.append(n)\n",
        "      losses.append(float(loss)/batch_size)\n",
        "      train_acc.append(get_accuracy(model, train = True))\n",
        "      val_acc.append(get_accuracy(model, train = True))\n",
        "      n+=1\n",
        "\n",
        "  plt.title(\"Training\")\n",
        "  plt.plot(iters, losses, label = \"Train\")\n",
        "  plt.plot(iters, val_acc, label = \"Validation\")\n",
        "  plt.xlabel(\"Iterations\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "  print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qc5gEBCwg_1"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k2xa5xKKjT1"
      },
      "source": [
        "### TAKES IN A DATALOADER AND PREDICTS THE ACCURACY OF THE MODEL ON THE DATA LOADED\n",
        "\n",
        "def get_accuracy(model, loader):\n",
        "  \n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for data in loader:\n",
        "    output = model(data[:12])\n",
        "    pred = output.max(1, keepdim = True)[1]\n",
        "    correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    total += data.shape[0]\n",
        "  return correct/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU2tVpTiSpZD"
      },
      "source": [
        "for data in training_loader:\n",
        "  print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xOMmWwUKMsk"
      },
      "source": [
        "model = neuralNetwork()\n",
        "\n",
        "training(model, data, training_loader, validation_loader, epochs, learning_rate, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La5wbnn6EWkL"
      },
      "source": [
        "### BELOW THIS POINT IS THE STUFF STILL NOT COMPLETED #########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PvaGtgYEzsv"
      },
      "source": [
        "test = get_data()\n",
        "print(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me6dd63Y-WfP"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0SdWQUjD3g5"
      },
      "source": [
        "### DEFINING HOW TO CALCULATE ACCURACY OF MODEL\n",
        "\n",
        "def accuracy(model, data_loader):\n",
        "  correct, total = 0, 0\n",
        "  for values, labels in data_loader:\n",
        "    output = model(values)\n",
        "    pred = output.max(1, keepdim=True)[1]\n",
        "    correct+=pred.eq(labels.view_as(pred)).sum().item()\n",
        "    total += labels.shape[0]\n",
        "  return correct/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px2eyWwLWFfA"
      },
      "source": [
        "### EXPERIMENTAL DATASET\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, list_IDs, labels):\n",
        "    self.labels = labels\n",
        "    self.list_IDs = list_IDs\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.list_IDS)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    ID = self.list_IDs[index]\n",
        "\n",
        "    X = torch.load('data/' + ID + '.pt')\n",
        "    y = self.labels[ID]\n",
        "\n",
        "    return X, y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dCZv9lmXTXL"
      },
      "source": [
        "### EXPERIMENTAL DATA USAGE\n",
        "\n",
        "training_set = Dataset()\n",
        "training_generator = torch.utils.data.DataLoader(training_set, **params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrcdPi81YPTV"
      },
      "source": [
        "### LOADING CSV FILE WITH PANDAS\n",
        "\n",
        "import pandas\n",
        "\n",
        "pandas.read_csv(directory).shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmeEfZA9eZAf"
      },
      "source": [
        "### PANDAS CLASS METHOD\n",
        "\n",
        "datum = fileDataset(directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVytpFK-X7tN"
      },
      "source": [
        "### PANDAS CLASS METHOD\n",
        "\n",
        "import pandas\n",
        "\n",
        "class fileDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, directory):\n",
        "    new_file = pandas.read_csv(directory)\n",
        "    data = new_file.iloc[:,1:(new_file.shape[1]-1)]\n",
        "    label = new_file.iloc[:,(new_file.shape[1]-1)]\n",
        "\n",
        "    self.data = torch.tensor(data, dtype = torch.float32)\n",
        "    self.label = torch.tensor(label)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx], self.label[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aed9GUINgu4S"
      },
      "source": [
        "### DEFINING A FUNCTION FOR RETRIEVING DATA\n",
        "def load_CSV():\n",
        "\n",
        "  ### OPENING CSV FILE\n",
        "  file = open(directory, \"r\")\n",
        "  retrieved = csv.reader(file)\n",
        "\n",
        "  data_size = -1\n",
        "  dictionary = {}\n",
        "  data = []\n",
        "\n",
        "  ### RETRIEVING DATA FROM CSV FILE\n",
        "  for row in retrieved:\n",
        "    data_size += 1 #Counts number of rows produced\n",
        "\n",
        "    if data_size == 0:\n",
        "      for i in range(len(row)):\n",
        "        dictionary[i] = row[i]\n",
        "      \n",
        "    else:\n",
        "      data.append(row)\n",
        "    \n",
        "  for i in data:\n",
        "    del i[0] #First column of data is index for data\n",
        "  del dictionary[0] #Delete corresponding class label to index of data\n",
        "  \n",
        "  return data, dictionary\n",
        "\n",
        "\n",
        "### DEFINING A FUNCTION FOR CLEANING DATA\n",
        "def clean_data(data, dictionary):\n",
        "  fail_count, temp_count = 0, 0\n",
        "\n",
        "  for i in range(len(data)):\n",
        "    row = data[i]\n",
        "    new_row = []\n",
        "\n",
        "    for j in range(len(row)):\n",
        "      test = row[j].split('.')\n",
        "      if row[j].isnumeric() or (len(test) == 2 and (test[0].isnumeric() and test[1].isnumeric())):\n",
        "        new_row.append(float(row[j]))\n",
        "\n",
        "      else:\n",
        "        del data[i]\n",
        "        break\n",
        "      \n",
        "      if j == (len(row)-1):\n",
        "        data[i] = new_row\n",
        "\n",
        "  return data, dictionary\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mBVAnUiqlUa"
      },
      "source": [
        "class labeledDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, data_list, labels):\n",
        "    self.landmarks_frame = labels\n",
        "    self.datum = data_list\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.landmarks_frame)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "\n",
        "    landmarks = np.array(self.landmarks_frame)\n",
        "    sample = {'datum': datum, 'landmarks': landmarks}\n",
        "\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "\n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}